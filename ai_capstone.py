# -*- coding: utf-8 -*-
"""AI capstone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qO7BojMX_3Zlz1JnwXKZtD-zvsMzde_B
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import pylab as pl
import numpy as np
import scipy.optimize as opt
from sklearn import preprocessing
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error
from xgboost import XGBRegressor
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
from scipy.stats import probplot

df_cycle = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CycleData.csv')

# Check for missing values
print("\n\nMissing Values of CycleData:\n")
print(df_cycle.isnull().sum())

# Remove missing values
df_cycle = df_cycle.dropna(subset=['Fuel Used'],axis=0)
df_cycle = df_cycle.dropna(axis=1)


X = df_cycle.drop('Fuel Used', axis=1)  # Features
y = df_cycle['Fuel Used']  # Target variable
# Take the object var only and change to int type
object_columns = X.select_dtypes(include=['object']).columns
label_encoders = {}
for col in object_columns:
    label_encoders[col] = LabelEncoder()
    X[col] = label_encoders[col].fit_transform(X[col])
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)
print(y.head())
print(X_train.head())

#initialize  model
xgb_regressor = XGBRegressor(objective='reg:squarederror', eval_metric='rmse', random_state=42)
xgb_regressor.fit(X_train, y_train)
# Predict
y_pred = xgb_regressor.predict(X_test)
# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

mae = mean_absolute_error(y_test, y_pred)
print("Mean Absolute Error:", mae)

rmse = mean_squared_error(y_test, y_pred, squared=False)
print("Root Mean Squared Error:", rmse)

# Calculate residuals
residuals = y_test - y_pred

# Residual Plot
plt.figure(figsize=(10, 6))
plt.scatter(y_pred, residuals, alpha=0.5)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residual Plot')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.show()

# Distribution of Errors
plt.figure(figsize=(10, 6))
sns.histplot(residuals, kde=True)
plt.title('Distribution of Errors')
plt.xlabel('Errors')
plt.ylabel('Density')
plt.show()

#hyperparameter search space
param_grid = {
    'n_estimators': [100, 200, 300, 400, 500],
    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],
    'max_depth': [3, 4, 5, 6, 7],
    'min_child_weight': [1, 2, 3, 4, 5],
    'gamma': [0, 0.1, 0.2, 0.3, 0.4],
    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
    'reg_alpha': [0, 0.1, 0.5, 1, 2],
    'reg_lambda': [0, 0.1, 0.5, 1, 2]
}
#Monte Carlo Simulation Parameters
num_simulations = 5
sample_size = 0.8

results = []
for i in range(num_simulations):
    X_sample, _, y_sample, _ = train_test_split(X, y, train_size=sample_size, random_state=i)
    xgb_regressor = XGBRegressor(objective='reg:squarederror', eval_metric='rmse', random_state=42)
    #Random Search
    random_search = RandomizedSearchCV(estimator=xgb_regressor, param_distributions=param_grid, n_iter=50,
                                       scoring='neg_mean_squared_error', cv=5, verbose=2, random_state=42, n_jobs=-1)
    random_search.fit(X_sample, y_sample)

    #Append Results
    results.append({
        'best_params': random_search.best_params_,
        'best_score': random_search.best_score_
    })
#convert results to dataframe
results_df = pd.DataFrame(results)

print("Mean best score:", results_df['best_score'].mean())
print("Standard deviation of best scores:", results_df['best_score'].std())
print("Best hyperparameters:")
print(results_df['best_params'].mode())

model_best_params = results_df['best_params'].mode().iloc[0]
for key, value in model_best_params.items():
    print(f"{key}: {value}")

# Initialize and train the XGBoost with optimized hyper parameters
best_params = {
    'subsample': 0.7,
    'reg_lambda': 0.5,
    'reg_alpha': 0.1,
    'n_estimators': 500,
    'min_child_weight': 4,
    'max_depth': 4,
    'learning_rate': 0.3,
    'gamma': 0,
    'colsample_bytree': 0.9
}
# Initialize XGBRegressor with best hyperparameters
xgb_regressor_best = XGBRegressor(objective='reg:squarederror', eval_metric='rmse', random_state=42, **best_params)
xgb_regressor_best.fit(X_train, y_train)
# Predict
y_pred = xgb_regressor_best.predict(X_test)
# Evaluate the model
mse_best = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse_best)

mae_best = mean_absolute_error(y_test, y_pred)
print("Mean Absolute Error:", mae_best)

rmse_best = mean_squared_error(y_test, y_pred, squared=False)
print("Root Mean Squared Error:", rmse_best)

# Calculate residuals
residuals = y_test - y_pred

# Residual Plot
plt.figure(figsize=(10, 6))
plt.scatter(y_pred, residuals, alpha=0.5)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Residual Plot')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.show()

# Distribution of Errors
plt.figure(figsize=(10, 6))
sns.histplot(residuals, kde=True)
plt.title('Distribution of Errors')
plt.xlabel('Errors')
plt.ylabel('Density')
plt.show()

#improvements
mse_percent= (mse - mse_best) / mse * 100
print("MSE improvement: {:.2f}%".format(mse_percent))

#k-cross validation

from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Define the number of folds for cross-validation
k = 5

# Initialize the cross-validation splitter
kf = KFold(n_splits=k, shuffle=True, random_state=42)

# Initialize your regression model (e.g., LinearRegression)
model = LinearRegression()

# Perform k-fold cross-validation and calculate regression metrics
mse_scores = -cross_val_score(xgb_regressor, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')
r2_scores = cross_val_score(xgb_regressor, X_train, y_train, cv=kf, scoring='r2')

print("Mean Squared Error (MSE) Scores for Each Fold:", mse_scores)
print("R-squared Scores for Each Fold:", r2_scores)
average_mse = mse_scores.mean()
print("Average Mean Squared Error (MSE):", average_mse)
average_r2 = r2_scores.mean()
print("Average R-squared:", average_r2)
#compare
mse_percent2= (average_mse - mse_best) / average_mse * 100
print("MSE improvement: {:.2f}%".format(mse_percent2))
